{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ca8f1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got float\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m obs_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m \u001b[38;5;241m*\u001b[39m (max_neighbors \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     26\u001b[0m total_obs_dim \u001b[38;5;241m=\u001b[39m obs_dim \u001b[38;5;241m*\u001b[39m scale\n\u001b[1;32m---> 28\u001b[0m maddpg \u001b[38;5;241m=\u001b[39m MADDPG(\n\u001b[0;32m     29\u001b[0m     n_agents\u001b[38;5;241m=\u001b[39mn_agents,\n\u001b[0;32m     30\u001b[0m     obs_dim\u001b[38;5;241m=\u001b[39mobs_dim,\n\u001b[0;32m     31\u001b[0m     total_obs_dim\u001b[38;5;241m=\u001b[39mtotal_obs_dim,\n\u001b[0;32m     32\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m     33\u001b[0m )\n",
      "File \u001b[1;32md:\\code\\python_project\\mywork\\MARL_MADDPG\\my\\model\\maddpg.py:29\u001b[0m, in \u001b[0;36mMADDPG.__init__\u001b[1;34m(self, n_agents, obs_dim, total_obs_dim, lr_actor, lr_critic, gamma, tau, buffer_size, batch_size, device)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# actors\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactors \u001b[38;5;241m=\u001b[39m [Actor(obs_dim)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_agents)]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_actors \u001b[38;5;241m=\u001b[39m [Actor(obs_dim)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_agents)]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# centralized critic\u001b[39;00m\n",
      "File \u001b[1;32md:\\code\\python_project\\mywork\\MARL_MADDPG\\my\\model\\agent.py:10\u001b[0m, in \u001b[0;36mActor.__init__\u001b[1;34m(self, obs_dim, act_dim)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs_dim, act_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m---> 10\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLinear(obs_dim, \u001b[38;5;241m128\u001b[39m),\n\u001b[0;32m     11\u001b[0m         nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m     12\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m),\n\u001b[0;32m     13\u001b[0m         nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m     14\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m128\u001b[39m, act_dim),\n\u001b[0;32m     15\u001b[0m         nn\u001b[38;5;241m.\u001b[39mSigmoid()  \u001b[38;5;66;03m# action ∈ [0,1]\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     )\n",
      "File \u001b[1;32md:\\develop\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:106\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m--> 106\u001b[0m     torch\u001b[38;5;241m.\u001b[39mempty((out_features, in_features), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs)\n\u001b[0;32m    107\u001b[0m )\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mTypeError\u001b[0m: empty(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got float\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from model.maddpg import MADDPG\n",
    "from runEnv import UAVEnv\n",
    "from env import load_different_scale_csv\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 设置不同的规模比例\n",
    "min_scale = 5\n",
    "middle_scale = 10\n",
    "max_scale = 20\n",
    "\n",
    "scale = min_scale\n",
    "n_agents = scale\n",
    "max_neighbors = scale / 3\n",
    "# ---------- 加载环境 ----------\n",
    "uavs, tasks, targets = load_different_scale_csv(\n",
    "    \"data/train/uav.csv\",\n",
    "    \"data/train/task.csv\",\n",
    "    size = scale\n",
    ")\n",
    "env = UAVEnv(uavs, targets, tasks)\n",
    "\n",
    "# 单个 UAV 观测维度（你 normalize 后的）\n",
    "obs_dim = 9 * (max_neighbors + 1) + 5\n",
    "total_obs_dim = obs_dim * scale\n",
    "\n",
    "maddpg = MADDPG(\n",
    "    n_agents=n_agents,\n",
    "    obs_dim=obs_dim,\n",
    "    total_obs_dim=total_obs_dim,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 训练 ----------\n",
    "episodes = 500\n",
    "\n",
    "for ep in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    ep_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # 构造 obs_all\n",
    "        obs_all = env.get_obs_all()\n",
    "        actions = maddpg.select_action(obs_all)\n",
    "        chosen = np.argmax(actions)\n",
    "        next_state, reward, done, _ = env.step(chosen)\n",
    "        if next_state is None:\n",
    "            break\n",
    "        next_obs_all = env.get_obs_all()\n",
    "\n",
    "        maddpg.buffer.push(\n",
    "            obs_all,\n",
    "            actions,\n",
    "            reward,\n",
    "            next_obs_all,\n",
    "            done\n",
    "        )\n",
    "        maddpg.update()\n",
    "        state = next_state\n",
    "        ep_reward += reward\n",
    "\n",
    "    print(f\"Episode {ep}, Reward: {ep_reward:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
